{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Program written by Scott Midgley, 2021\n",
    " Scope: To train and test GBDT models for band gap energy screening in the configuraional space of MgO-ZnO solid solutions. \n",
    " \n",
    " **Note** you will need to set the repo path to tell the code where to look for data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "### USER INPUT REQUIRED ###\n",
    "\n",
    "# Please paste in the path to the repositiory here an comment/uncomment as needed.\n",
    "# E.g. rundir = r'C:\\Users\\<user>\\Desktop\\repository'\n",
    "\n",
    "# Windows path\n",
    "#repodir = r'<windows\\path\\here>'\n",
    "\n",
    "#Unix path\n",
    "#repodir = '<unix/path/here>' \n",
    "repodir = r'/home/mts87985/ml-thermo/Machine-Learning-for-Solid-Solutions/repository/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "### USER INPUT REQUIRED ###\n",
    "\n",
    "# Define percentage of training data to use for training. \n",
    "#split = 10\n",
    "#split = 50\n",
    "split = 80\n",
    "#split = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import modules. \n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "import pickle\n",
    "import time\n",
    "from sklearn import datasets, ensemble\n",
    "from sklearn import metrics \n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import GridSearchCV   \n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the data\n",
    "\n",
    "Note we do not shuffle in this case. The data was shuffled when created and we are keeping it un-shuffled here so that the order is the same as that used in the paper. However, you are free to add a shuffle if you like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import data and shuffle (optional).\n",
    "eners = pd.read_pickle(repodir + 'repository-data/coulomb_matrix/input_data_cme.pkl')\n",
    "#eners = eners.sample(frac=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data frame into training, validation, and testing data. \n",
    "if split == int(10):\n",
    "    e_train = eners.iloc[1608:2412] #10% of data for training\n",
    "elif split == int(30):\n",
    "    e_train = eners.iloc[1608:4021] #30% of data for training\n",
    "elif split == int(50):\n",
    "    e_train = eners.iloc[1608:5630] #50% of data for training\n",
    "elif split == int(80):\n",
    "    e_train = eners.iloc[1608:] #80% of data for training\n",
    "else:\n",
    "    print('Error: please choose a valid train/test split.')\n",
    "e_val = eners.iloc[804:1608] #10% of data for validation\n",
    "e_test = eners.iloc[:804] #10% of data for testing model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert Pandas columns to Numpy arrays. Reshaping to obtain array of nested brackets. \n",
    "Xtrain = e_train['Coulomb'].to_numpy()\n",
    "ytrain = e_train['BGE'].to_numpy()\n",
    "Xtrain = np.stack(Xtrain)\n",
    "ytrain= np.stack(ytrain) \n",
    "Xval = e_val['Coulomb'].to_numpy()\n",
    "yval = e_val['BGE'].to_numpy()\n",
    "Xval = np.stack(Xval)\n",
    "yval= np.stack(yval)\n",
    "Xtest = e_test['Coulomb'].to_numpy()\n",
    "ytest = e_test['BGE'].to_numpy()\n",
    "Xtest = np.stack(Xtest)\n",
    "ytest = np.stack(ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingRegressor(learning_rate=0.01, max_depth=4, min_samples_split=5,\n",
       "                          n_estimators=1000)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define GBDT hyperparameters. \n",
    "params = {'n_estimators': 1000,\n",
    "          'max_depth': 4,\n",
    "          'min_samples_split': 5,\n",
    "          'learning_rate': 0.01,\n",
    "          'loss': 'ls'}\n",
    "reg = ensemble.GradientBoostingRegressor(**params)\n",
    "reg.fit(Xtrain, ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test GBDT model. \n",
    "ypred = reg.predict(Xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mae =  0.009730731273487555\n"
     ]
    }
   ],
   "source": [
    "# Print metrics.\n",
    "mae = (mean_absolute_error(ytest, ypred))\n",
    "print('mae = ', mae)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
