{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Program written by Scott Midgley, 2021\n",
    " Scope: To train and test MLP models for band gap energy screening in the configuraional space of MgO-ZnO solid solutions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "### USER INPUT REQUIRED ###\n",
    "\n",
    "# Please paste in the path to the repositiory here an comment/uncomment as needed.\n",
    "# E.g. rundir = r'C:\\Users\\<user>\\Desktop\\repository'\n",
    "\n",
    "# Windows path\n",
    "#repodir = r'<windows\\path\\here>'\n",
    "\n",
    "#Unix path\n",
    "#repodir = '<unix/path/here>'\n",
    "repodir = r'/home/mts87985/ml-thermo/Machine-Learning-for-Solid-Solutions/repository/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "### USER INPUT REQUIRED ###\n",
    "\n",
    "# Define percentage of training data to use for training. \n",
    "split = 10\n",
    "#split = 50\n",
    "#split = 80\n",
    "#split = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import modules.\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import BatchNormalization, Dropout\n",
    "from tensorflow.keras.optimizers import Adam #Stochasic gradient descent method optimising weights and activations\n",
    "import copy\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "import time\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import pickle\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mlp_shallow(dropout_rate=0.1):\n",
    "    # Define MLP architecture. \n",
    "    model = Sequential()\n",
    "    model.add(Dense(64, input_dim=Xtrain[0].shape[0], activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    if dropout_rate > 0:\n",
    "        model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(32, activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    if dropout_rate > 0:\n",
    "        model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(1, activation='linear'))\n",
    "    return model\n",
    "    \n",
    "def mlp_deep(dropout_rate=0.1):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(256, input_dim=Xtrain[0].shape[0], activation='relu')) #Set 128 standard neurons with relu initial activation\n",
    "    model.add(BatchNormalization())\n",
    "    if dropout_rate > 0:\n",
    "        model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    if dropout_rate > 0:\n",
    "        model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    if dropout_rate > 0:\n",
    "        model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(32, activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    if dropout_rate > 0:\n",
    "        model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(1, activation='linear'))\n",
    "    return model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clear any existing Tensorflow data from cache.\n",
    "tf.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the data\n",
    "\n",
    "Note we do not shuffle in this case. The data was shuffled when created and we are keeping it un-shuffled here so that the order is the same as that used in the paper. However, you are free to add a shuffle if you like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import data and shuffle (optional).\n",
    "eners = pd.read_pickle(repodir + 'repository-data/coulomb_matrix/input_data_cme.pkl')\n",
    "#eners = eners.sample(frac=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data frame into training, validation, and testing data. \n",
    "if split == int(10):\n",
    "    e_train = eners.iloc[1608:2412] #10% of data for training\n",
    "elif split == int(30):\n",
    "    e_train = eners.iloc[1608:4021] #30% of data for training\n",
    "elif split == int(50):\n",
    "    e_train = eners.iloc[1608:5630] #50% of data for training\n",
    "elif split == int(80):\n",
    "    e_train = eners.iloc[1608:] #80% of data for training\n",
    "else:\n",
    "    print('Error: please choose a valid train/test split.')\n",
    "e_val = eners.iloc[804:1608] #10% of data for validation\n",
    "e_test = eners.iloc[:804] #10% of data for testing model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training data points =  804\n"
     ]
    }
   ],
   "source": [
    "# Print number of training data points\n",
    "print('Number of training data points = ', len(e_train))\n",
    "# Convert Pandas columns to Numpy arrays. Reshaping to obtain array of nested brackets. \n",
    "Xtrain = e_train['Coulomb'].to_numpy()\n",
    "ytrain = e_train['BGE'].to_numpy()\n",
    "Xtrain = np.stack(Xtrain)\n",
    "ytrain= np.stack(ytrain) \n",
    "Xval = e_val['Coulomb'].to_numpy()\n",
    "yval = e_val['BGE'].to_numpy()\n",
    "Xval = np.stack(Xval)\n",
    "yval= np.stack(yval)\n",
    "Xtest = e_test['Coulomb'].to_numpy()\n",
    "ytest = e_test['BGE'].to_numpy()\n",
    "Xtest = np.stack(Xtest)\n",
    "ytest = np.stack(ytest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load a pre-trained model\n",
    "\n",
    "In the first instance we can load a pre-trained model and test how it works.\n",
    "\n",
    "The model weights are available in the Zenodo repo. If you download them and follow the directions saved weights will now be in `data/weights/`.\n",
    "\n",
    "The models available are:\n",
    "* Trained on 10% data: `mlp-10.h5`\n",
    "* Trained on 30% data: `mlp-30.h5`\n",
    "* Trained on 50% data: `mlp-50.h5`\n",
    "* Trained on 80% data: `mlp-80.h5`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 256)               16640     \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 32)                128       \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 61,825\n",
      "Trainable params: 60,865\n",
      "Non-trainable params: 960\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.load_model(repodir + 'repository-data/coulomb_matrix/mlp_trained_models/mlp-10.h5')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try this model on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mae =  0.01421831452156182\n"
     ]
    }
   ],
   "source": [
    "# Test model. \n",
    "ypred = model.predict(Xtest)\n",
    "# Print metric.\n",
    "mae = (mean_absolute_error(ytest, ypred))\n",
    "print('mae = ', mae)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train a model from scrach \n",
    "\n",
    "You can retrain a new model on any amount of the data that you would like to use.\n",
    "Note - the model will probably take around 8000 epochs to reach the stopping creteria prescribed below (these are the criteria used in the paper).\n",
    "\n",
    "You can build either the shallow or the deep network using the `shallow_mlp` and `deep_mlp` functions respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define MLP architecture. \n",
    "model = mlp_deep(dropout_rate=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 256)               16640     \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 32)                128       \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 61,825\n",
      "Trainable params: 60,865\n",
      "Non-trainable params: 960\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Summarize model trainable parameters. \n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define early stopping parameters. \n",
    "stopping =  EarlyStopping(monitor='val_mae', patience=750, verbose=0, mode='auto', restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define MLP hyperparameters. \n",
    "ad = Adam(learning_rate=1e-4, beta_1=0.9, beta_2=0.999, amsgrad=False) # Model creation\n",
    "model.compile(loss='mae', optimizer=ad, metrics=['mae']) # Model config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "4/4 [==============================] - 2s 205ms/step - loss: 3.4231 - mae: 3.4231 - val_loss: 95.9755 - val_mae: 95.9755\n",
      "Epoch 2/100\n",
      "4/4 [==============================] - 0s 68ms/step - loss: 3.4259 - mae: 3.4259 - val_loss: 79.4755 - val_mae: 79.4755\n",
      "Epoch 3/100\n",
      "4/4 [==============================] - 0s 60ms/step - loss: 3.3886 - mae: 3.3886 - val_loss: 67.9184 - val_mae: 67.9184\n",
      "Epoch 4/100\n",
      "4/4 [==============================] - 0s 86ms/step - loss: 3.4752 - mae: 3.4752 - val_loss: 59.9841 - val_mae: 59.9841\n",
      "Epoch 5/100\n",
      "4/4 [==============================] - 0s 60ms/step - loss: 3.4194 - mae: 3.4194 - val_loss: 54.1360 - val_mae: 54.1360\n",
      "Epoch 6/100\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 3.4483 - mae: 3.4483 - val_loss: 50.4731 - val_mae: 50.4731\n",
      "Epoch 7/100\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 3.4402 - mae: 3.4402 - val_loss: 46.7528 - val_mae: 46.7528\n",
      "Epoch 8/100\n",
      "4/4 [==============================] - 0s 61ms/step - loss: 3.3726 - mae: 3.3726 - val_loss: 44.1826 - val_mae: 44.1826\n",
      "Epoch 9/100\n",
      "4/4 [==============================] - 0s 104ms/step - loss: 3.4546 - mae: 3.4546 - val_loss: 41.5335 - val_mae: 41.5335\n",
      "Epoch 10/100\n",
      "4/4 [==============================] - 0s 96ms/step - loss: 3.3690 - mae: 3.3690 - val_loss: 38.8249 - val_mae: 38.8249\n",
      "Epoch 11/100\n",
      "4/4 [==============================] - 0s 85ms/step - loss: 3.4177 - mae: 3.4177 - val_loss: 36.5707 - val_mae: 36.5707\n",
      "Epoch 12/100\n",
      "4/4 [==============================] - 0s 82ms/step - loss: 3.4202 - mae: 3.4202 - val_loss: 33.9889 - val_mae: 33.9889\n",
      "Epoch 13/100\n",
      "4/4 [==============================] - 0s 75ms/step - loss: 3.4017 - mae: 3.4017 - val_loss: 32.6072 - val_mae: 32.6072\n",
      "Epoch 14/100\n",
      "4/4 [==============================] - 0s 56ms/step - loss: 3.4621 - mae: 3.4621 - val_loss: 30.1125 - val_mae: 30.1125\n",
      "Epoch 15/100\n",
      "4/4 [==============================] - 0s 109ms/step - loss: 3.4132 - mae: 3.4132 - val_loss: 28.5234 - val_mae: 28.5234\n",
      "Epoch 16/100\n",
      "4/4 [==============================] - 0s 86ms/step - loss: 3.4093 - mae: 3.4093 - val_loss: 26.6925 - val_mae: 26.6925\n",
      "Epoch 17/100\n",
      "4/4 [==============================] - 0s 79ms/step - loss: 3.4238 - mae: 3.4238 - val_loss: 25.4276 - val_mae: 25.4276\n",
      "Epoch 18/100\n",
      "4/4 [==============================] - 0s 75ms/step - loss: 3.3573 - mae: 3.3573 - val_loss: 24.0112 - val_mae: 24.0112\n",
      "Epoch 19/100\n",
      "4/4 [==============================] - 0s 108ms/step - loss: 3.3842 - mae: 3.3842 - val_loss: 22.9484 - val_mae: 22.9484\n",
      "Epoch 20/100\n",
      "4/4 [==============================] - 0s 82ms/step - loss: 3.3557 - mae: 3.3557 - val_loss: 21.9285 - val_mae: 21.9285\n",
      "Epoch 21/100\n",
      "4/4 [==============================] - 0s 51ms/step - loss: 3.3779 - mae: 3.3779 - val_loss: 21.1043 - val_mae: 21.1043\n",
      "Epoch 22/100\n",
      "4/4 [==============================] - 0s 84ms/step - loss: 3.2923 - mae: 3.2923 - val_loss: 19.9196 - val_mae: 19.9196\n",
      "Epoch 23/100\n",
      "4/4 [==============================] - 0s 84ms/step - loss: 3.3087 - mae: 3.3087 - val_loss: 18.6536 - val_mae: 18.6536\n",
      "Epoch 24/100\n",
      "4/4 [==============================] - 0s 108ms/step - loss: 3.4062 - mae: 3.4062 - val_loss: 17.6272 - val_mae: 17.6272\n",
      "Epoch 25/100\n",
      "4/4 [==============================] - 0s 91ms/step - loss: 3.3345 - mae: 3.3345 - val_loss: 16.7055 - val_mae: 16.7055\n",
      "Epoch 26/100\n",
      "4/4 [==============================] - 0s 110ms/step - loss: 3.3669 - mae: 3.3669 - val_loss: 15.7486 - val_mae: 15.7486\n",
      "Epoch 27/100\n",
      "4/4 [==============================] - 0s 94ms/step - loss: 3.3759 - mae: 3.3759 - val_loss: 14.7370 - val_mae: 14.7370\n",
      "Epoch 28/100\n",
      "4/4 [==============================] - 0s 85ms/step - loss: 3.4298 - mae: 3.4298 - val_loss: 14.1480 - val_mae: 14.1480\n",
      "Epoch 29/100\n",
      "4/4 [==============================] - 0s 50ms/step - loss: 3.3705 - mae: 3.3705 - val_loss: 13.2267 - val_mae: 13.2267\n",
      "Epoch 30/100\n",
      "4/4 [==============================] - 0s 73ms/step - loss: 3.3125 - mae: 3.3125 - val_loss: 12.4076 - val_mae: 12.4076\n",
      "Epoch 31/100\n",
      "4/4 [==============================] - 0s 74ms/step - loss: 3.2975 - mae: 3.2975 - val_loss: 11.6196 - val_mae: 11.6196\n",
      "Epoch 32/100\n",
      "4/4 [==============================] - 0s 92ms/step - loss: 3.3880 - mae: 3.3880 - val_loss: 10.9611 - val_mae: 10.9611\n",
      "Epoch 33/100\n",
      "4/4 [==============================] - 0s 77ms/step - loss: 3.3537 - mae: 3.3537 - val_loss: 10.4112 - val_mae: 10.4112\n",
      "Epoch 34/100\n",
      "4/4 [==============================] - 0s 80ms/step - loss: 3.3833 - mae: 3.3833 - val_loss: 9.4148 - val_mae: 9.4148\n",
      "Epoch 35/100\n",
      "4/4 [==============================] - 0s 74ms/step - loss: 3.3558 - mae: 3.3558 - val_loss: 8.4360 - val_mae: 8.4360\n",
      "Epoch 36/100\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 3.2906 - mae: 3.2906 - val_loss: 7.6364 - val_mae: 7.6364\n",
      "Epoch 37/100\n",
      "4/4 [==============================] - 0s 71ms/step - loss: 3.3120 - mae: 3.3120 - val_loss: 7.0770 - val_mae: 7.0770\n",
      "Epoch 38/100\n",
      "4/4 [==============================] - 0s 81ms/step - loss: 3.2729 - mae: 3.2729 - val_loss: 6.6476 - val_mae: 6.6476\n",
      "Epoch 39/100\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 3.2838 - mae: 3.2838 - val_loss: 6.3627 - val_mae: 6.3627\n",
      "Epoch 40/100\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 3.3814 - mae: 3.3814 - val_loss: 5.9700 - val_mae: 5.9700\n",
      "Epoch 41/100\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 3.3822 - mae: 3.3822 - val_loss: 5.6523 - val_mae: 5.6523\n",
      "Epoch 42/100\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 3.3474 - mae: 3.3474 - val_loss: 5.2792 - val_mae: 5.2792\n",
      "Epoch 43/100\n",
      "4/4 [==============================] - 0s 57ms/step - loss: 3.3229 - mae: 3.3229 - val_loss: 4.9248 - val_mae: 4.9248\n",
      "Epoch 44/100\n",
      "4/4 [==============================] - 0s 84ms/step - loss: 3.2685 - mae: 3.2685 - val_loss: 4.8509 - val_mae: 4.8509\n",
      "Epoch 45/100\n",
      "4/4 [==============================] - 0s 72ms/step - loss: 3.3093 - mae: 3.3093 - val_loss: 4.8107 - val_mae: 4.8107\n",
      "Epoch 46/100\n",
      "4/4 [==============================] - 0s 74ms/step - loss: 3.3365 - mae: 3.3365 - val_loss: 4.6652 - val_mae: 4.6652\n",
      "Epoch 47/100\n",
      "4/4 [==============================] - 0s 86ms/step - loss: 3.2661 - mae: 3.2661 - val_loss: 4.4180 - val_mae: 4.4180\n",
      "Epoch 48/100\n",
      "4/4 [==============================] - 0s 97ms/step - loss: 3.3056 - mae: 3.3056 - val_loss: 4.3459 - val_mae: 4.3459\n",
      "Epoch 49/100\n",
      "4/4 [==============================] - 0s 93ms/step - loss: 3.2819 - mae: 3.2819 - val_loss: 3.9728 - val_mae: 3.9728\n",
      "Epoch 50/100\n",
      "4/4 [==============================] - 0s 88ms/step - loss: 3.2680 - mae: 3.2680 - val_loss: 3.6136 - val_mae: 3.6136\n",
      "Epoch 51/100\n",
      "4/4 [==============================] - 0s 70ms/step - loss: 3.2627 - mae: 3.2627 - val_loss: 3.2802 - val_mae: 3.2802\n",
      "Epoch 52/100\n",
      "4/4 [==============================] - 0s 71ms/step - loss: 3.2659 - mae: 3.2659 - val_loss: 2.9128 - val_mae: 2.9128\n",
      "Epoch 53/100\n",
      "4/4 [==============================] - 0s 56ms/step - loss: 3.2902 - mae: 3.2902 - val_loss: 2.6655 - val_mae: 2.6655\n",
      "Epoch 54/100\n",
      "4/4 [==============================] - 0s 88ms/step - loss: 3.2650 - mae: 3.2650 - val_loss: 2.4960 - val_mae: 2.4960\n",
      "Epoch 55/100\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 3.2819 - mae: 3.2819 - val_loss: 2.2967 - val_mae: 2.2967\n",
      "Epoch 56/100\n",
      "4/4 [==============================] - 0s 67ms/step - loss: 3.3259 - mae: 3.3259 - val_loss: 2.0215 - val_mae: 2.0215\n",
      "Epoch 57/100\n",
      "4/4 [==============================] - 0s 83ms/step - loss: 3.2539 - mae: 3.2539 - val_loss: 1.9214 - val_mae: 1.9214\n",
      "Epoch 58/100\n",
      "4/4 [==============================] - 0s 78ms/step - loss: 3.2743 - mae: 3.2743 - val_loss: 1.8433 - val_mae: 1.8433\n",
      "Epoch 59/100\n",
      "4/4 [==============================] - 0s 86ms/step - loss: 3.2575 - mae: 3.2575 - val_loss: 1.6594 - val_mae: 1.6594\n",
      "Epoch 60/100\n",
      "4/4 [==============================] - 0s 61ms/step - loss: 3.2920 - mae: 3.2920 - val_loss: 1.5613 - val_mae: 1.5613\n",
      "Epoch 61/100\n",
      "4/4 [==============================] - 0s 67ms/step - loss: 3.1935 - mae: 3.1935 - val_loss: 1.4694 - val_mae: 1.4694\n",
      "Epoch 62/100\n",
      "4/4 [==============================] - 0s 59ms/step - loss: 3.3228 - mae: 3.3228 - val_loss: 1.3318 - val_mae: 1.3318\n",
      "Epoch 63/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 48ms/step - loss: 3.2380 - mae: 3.2380 - val_loss: 1.1997 - val_mae: 1.1997\n",
      "Epoch 64/100\n",
      "4/4 [==============================] - 0s 90ms/step - loss: 3.2282 - mae: 3.2282 - val_loss: 1.0758 - val_mae: 1.0758\n",
      "Epoch 65/100\n",
      "4/4 [==============================] - 0s 80ms/step - loss: 3.2575 - mae: 3.2575 - val_loss: 1.0158 - val_mae: 1.0158\n",
      "Epoch 66/100\n",
      "4/4 [==============================] - 0s 67ms/step - loss: 3.1935 - mae: 3.1935 - val_loss: 0.9552 - val_mae: 0.9552\n",
      "Epoch 67/100\n",
      "4/4 [==============================] - 0s 84ms/step - loss: 3.2532 - mae: 3.2532 - val_loss: 0.9138 - val_mae: 0.9138\n",
      "Epoch 68/100\n",
      "4/4 [==============================] - 0s 83ms/step - loss: 3.1977 - mae: 3.1977 - val_loss: 0.8951 - val_mae: 0.8951\n",
      "Epoch 69/100\n",
      "4/4 [==============================] - 0s 74ms/step - loss: 3.2413 - mae: 3.2413 - val_loss: 0.8929 - val_mae: 0.8929\n",
      "Epoch 70/100\n",
      "4/4 [==============================] - 0s 61ms/step - loss: 3.1896 - mae: 3.1896 - val_loss: 0.9223 - val_mae: 0.9223\n",
      "Epoch 71/100\n",
      "4/4 [==============================] - 0s 50ms/step - loss: 3.2045 - mae: 3.2045 - val_loss: 0.9616 - val_mae: 0.9616\n",
      "Epoch 72/100\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 3.1881 - mae: 3.1881 - val_loss: 1.0173 - val_mae: 1.0173\n",
      "Epoch 73/100\n",
      "4/4 [==============================] - 0s 88ms/step - loss: 3.1898 - mae: 3.1898 - val_loss: 1.1447 - val_mae: 1.1447\n",
      "Epoch 74/100\n",
      "4/4 [==============================] - 0s 76ms/step - loss: 3.1723 - mae: 3.1723 - val_loss: 1.2202 - val_mae: 1.2202\n",
      "Epoch 75/100\n",
      "4/4 [==============================] - 0s 78ms/step - loss: 3.1823 - mae: 3.1823 - val_loss: 1.2704 - val_mae: 1.2704\n",
      "Epoch 76/100\n",
      "4/4 [==============================] - 0s 76ms/step - loss: 3.2145 - mae: 3.2145 - val_loss: 1.3386 - val_mae: 1.3386\n",
      "Epoch 77/100\n",
      "4/4 [==============================] - 0s 71ms/step - loss: 3.2005 - mae: 3.2005 - val_loss: 1.3311 - val_mae: 1.3311\n",
      "Epoch 78/100\n",
      "4/4 [==============================] - 0s 76ms/step - loss: 3.1986 - mae: 3.1986 - val_loss: 1.3586 - val_mae: 1.3586\n",
      "Epoch 79/100\n",
      "4/4 [==============================] - 0s 68ms/step - loss: 3.1687 - mae: 3.1687 - val_loss: 1.3876 - val_mae: 1.3876\n",
      "Epoch 80/100\n",
      "4/4 [==============================] - 0s 61ms/step - loss: 3.2201 - mae: 3.2201 - val_loss: 1.4211 - val_mae: 1.4211\n",
      "Epoch 81/100\n",
      "4/4 [==============================] - 0s 83ms/step - loss: 3.1959 - mae: 3.1959 - val_loss: 1.4897 - val_mae: 1.4897\n",
      "Epoch 82/100\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 3.1647 - mae: 3.1647 - val_loss: 1.5606 - val_mae: 1.5606\n",
      "Epoch 83/100\n",
      "4/4 [==============================] - 0s 54ms/step - loss: 3.1723 - mae: 3.1723 - val_loss: 1.6729 - val_mae: 1.6729\n",
      "Epoch 84/100\n",
      "4/4 [==============================] - 0s 50ms/step - loss: 3.1407 - mae: 3.1407 - val_loss: 1.6997 - val_mae: 1.6997\n",
      "Epoch 85/100\n",
      "4/4 [==============================] - 0s 60ms/step - loss: 3.1599 - mae: 3.1599 - val_loss: 1.7070 - val_mae: 1.7070\n",
      "Epoch 86/100\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 3.0915 - mae: 3.0915 - val_loss: 1.7450 - val_mae: 1.7450\n",
      "Epoch 87/100\n",
      "4/4 [==============================] - 0s 67ms/step - loss: 3.1533 - mae: 3.1533 - val_loss: 1.7804 - val_mae: 1.7804\n",
      "Epoch 88/100\n",
      "4/4 [==============================] - 0s 76ms/step - loss: 3.0734 - mae: 3.0734 - val_loss: 1.7739 - val_mae: 1.7739\n",
      "Epoch 89/100\n",
      "4/4 [==============================] - 0s 59ms/step - loss: 3.2062 - mae: 3.2062 - val_loss: 1.8117 - val_mae: 1.8117\n",
      "Epoch 90/100\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 3.1963 - mae: 3.1963 - val_loss: 1.8880 - val_mae: 1.8880\n",
      "Epoch 91/100\n",
      "4/4 [==============================] - 0s 67ms/step - loss: 3.1123 - mae: 3.1123 - val_loss: 1.9114 - val_mae: 1.9114\n",
      "Epoch 92/100\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 3.1355 - mae: 3.1355 - val_loss: 1.9291 - val_mae: 1.9291\n",
      "Epoch 93/100\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 3.1307 - mae: 3.1307 - val_loss: 2.0022 - val_mae: 2.0022\n",
      "Epoch 94/100\n",
      "4/4 [==============================] - 0s 52ms/step - loss: 3.1827 - mae: 3.1827 - val_loss: 2.0274 - val_mae: 2.0274\n",
      "Epoch 95/100\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 3.0761 - mae: 3.0761 - val_loss: 2.0588 - val_mae: 2.0588\n",
      "Epoch 96/100\n",
      "4/4 [==============================] - 0s 52ms/step - loss: 3.1254 - mae: 3.1254 - val_loss: 2.0820 - val_mae: 2.0820\n",
      "Epoch 97/100\n",
      "4/4 [==============================] - 0s 80ms/step - loss: 3.1646 - mae: 3.1646 - val_loss: 2.1166 - val_mae: 2.1166\n",
      "Epoch 98/100\n",
      "4/4 [==============================] - 0s 81ms/step - loss: 3.1743 - mae: 3.1743 - val_loss: 2.1137 - val_mae: 2.1137\n",
      "Epoch 99/100\n",
      "4/4 [==============================] - 0s 57ms/step - loss: 3.1214 - mae: 3.1214 - val_loss: 2.1280 - val_mae: 2.1280\n",
      "Epoch 100/100\n",
      "4/4 [==============================] - 0s 56ms/step - loss: 3.0469 - mae: 3.0469 - val_loss: 2.1513 - val_mae: 2.1513\n"
     ]
    }
   ],
   "source": [
    "# Train MLP. \n",
    "history = model.fit(Xtrain, ytrain, epochs=100, batch_size=256, verbose=1, validation_data=(Xval, yval), callbacks=[stopping]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['loss', 'mae', 'val_loss', 'val_mae'])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'Training Epoch')"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plote validation MAE vs number of training epochs. \n",
    "print(history.history.keys())\n",
    "plt.plot(history.history['mae'])\n",
    "plt.plot(history.history['val_mae'])\n",
    "plt.ylabel('Mean Absolute Error')\n",
    "plt.xlabel('Training Epoch')\n",
    "#plt.ylim(0,1)\n",
    "#plt.savefig('val-mae-zoom.png')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
